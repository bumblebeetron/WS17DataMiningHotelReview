{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk import ngrams\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Autocomplete():\n",
    "\n",
    "\n",
    "    def __init__(self, model_path=\"./\", sentences=None, n_model=3, n_candidates=10, match_model=\"middle\",\n",
    "                 min_freq=5, punctuations=\"\"\"!\"#$%&\\'()*+,./:;<=>?@[\\\\]^_{|}~\"\"\", lowercase=True):\n",
    "        # Model parameters\n",
    "        # order of the n-gram to use for the autocomplete\n",
    "        self.n_model = n_model\n",
    "        # number of candidates suggested sentences to show\n",
    "        self.n_candidates = n_candidates\n",
    "        # path to the folder that stores the language model\n",
    "        self.model_path = model_path\n",
    "        # type of autocomplete model\n",
    "        # `start`, `end` of `middle`\n",
    "        self.match_model = match_model\n",
    "        # do not consider ngrams that appear less than this value when generating the language model\n",
    "        self.min_freq = min_freq\n",
    "        # punctuations to remove\n",
    "        self.punctuations = punctuations\n",
    "        # lowercase the sentences?\n",
    "        self.lowercase = lowercase\n",
    "        # list of sentences to use to train the model\n",
    "        if sentences is None:\n",
    "            sentences = []\n",
    "        self.sentences = sentences\n",
    "\n",
    "        if not os.path.isdir(self.model_path):\n",
    "            os.makedirs(self.model_path)\n",
    "\n",
    "        # loading the language model\n",
    "        for N in range(1, self.n_model + 1):\n",
    "            filename = self.model_path + \"/\" + str(N) + \"-grams.pickle\"\n",
    "            if not os.path.exists(filename):\n",
    "                # if no language model is found, then it is computed\n",
    "                # remove the dashes and the bendy apostrophe\n",
    "                if not self.sentences:\n",
    "                    raise Exception(\"You need to give a sample sentences to train the model!\")\n",
    "                self.compute_language_model()\n",
    "\n",
    "        # ngrams_freqs is a dictionary whose keys are the ngrams labels and the values their counts\n",
    "        self.ngrams_freqs = dict()\n",
    "        for N in range(1, self.n_model + 1):\n",
    "            filename = self.model_path + \"/\" + str(N) + \"-grams.pickle\"\n",
    "            with open(filename, \"rb\") as f:\n",
    "                self.ngrams_freqs[N] = pickle.load(f)\n",
    "\n",
    "        # saving the ngrams_freqs keys in a separate dictionary\n",
    "        self.ngrams_keys = dict()\n",
    "        for N in range(1, self.n_model + 1):\n",
    "            self.ngrams_keys[N] = list(self.ngrams_freqs[N].keys())\n",
    "\n",
    "        # saving the total counts\n",
    "        self.total_counts = [sum(self.ngrams_freqs[N].values()) for N in range(1, self.n_model + 1)]\n",
    "\n",
    "\n",
    "    def get_ngrams(self, sentence, n=1):\n",
    "        \"\"\"\n",
    "        Given a sentence returns a list of its n-grams\n",
    "        \"\"\"\n",
    "        # remove punctuation\n",
    "        if self.punctuations != \"\":\n",
    "            sentence = re.sub('[' + self.punctuations + ']', ' ', sentence).strip()\n",
    "        if self.lowercase:\n",
    "            sentence = sentence.lower()\n",
    "        # generate tokens\n",
    "        if n > 1:\n",
    "            sentence = [\" \".join(n) for n in ngrams(sentence.split(), n, pad_right=True, right_pad_symbol='</END>')]\n",
    "        else:\n",
    "            sentence = sentence.split()\n",
    "        # return the token\n",
    "        # filter for empty string\n",
    "        return list(filter(None, sentence))\n",
    "\n",
    "\n",
    "    def compute_language_model(self):\n",
    "        \"\"\"\n",
    "        Given a list of sentences compute the n-grams\n",
    "        \"\"\"\n",
    "        if len(self.sentences) < 1e4:\n",
    "            for N in range(1, self.n_model + 1):\n",
    "                ngrams_list = []\n",
    "                for sentence in self.sentences:\n",
    "                    ngrams_sentence = self.get_ngrams(sentence, n=N)\n",
    "                    ngrams_list.extend(ngrams_sentence)\n",
    "                ngrams_freqs = Counter(ngrams_list)\n",
    "                filename = self.model_path + \"/\" + str(N) + \"-grams.pickle\"\n",
    "                with open(filename, \"wb\") as f:\n",
    "                    pickle.dump(ngrams_freqs, f)\n",
    "                print(\"Saving the %s-grams in %s\" % (N, filename))\n",
    "        else:\n",
    "            try:\n",
    "                from pyspark import SparkContext, SparkConf\n",
    "            except:\n",
    "                raise ImportError(\"pySpark not found! Please go to http://spark.apache.org/downloads.html\")\n",
    "            else:\n",
    "                # If there are more than 100,000 sentences use Spark to compute the n-grams\n",
    "                conf = SparkConf().setMaster(\"local\").setAppName(\"ComputeLanguageModel\")\n",
    "                sc = SparkContext(conf=conf)\n",
    "                sentences = sc.parallelize(self.sentences)\n",
    "\n",
    "                for N in range(1, self.n_model + 1):\n",
    "                    ngrams_freqs = sentences.flatMap(lambda x: self.get_ngrams(x, n=N))\n",
    "                    ngrams_freqs = ngrams_freqs.map(lambda word: (word, 1)).reduceByKey(lambda x, y: x + y).collect()\n",
    "                    ngrams_freqs.sort(key=lambda x: -x[1])\n",
    "                    ngrams_freqs = list(filter(lambda x: x[1] > self.min_freq, ngrams_freqs))\n",
    "                    ngrams_freqs = dict(ngrams_freqs)\n",
    "                    filename = self.model_path + \"/\" + str(N) + \"-grams.pickle\"\n",
    "                    with open(filename, \"wb\") as f:\n",
    "                        pickle.dump(ngrams_freqs, f)\n",
    "                        print(\"Saving the %s-grams in %s\" % (N, filename))\n",
    "\n",
    "                sc.stop()\n",
    "\n",
    "\n",
    "    def compute_prob_sentence(self, sentence):\n",
    "        \"\"\"\n",
    "        Given a sentence, return the log probability of that sentence using the n-gram approximation\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        if sentence != \"\":\n",
    "            total_prob = 0\n",
    "            pieces = sentence.split()\n",
    "            for i in range(1, len(pieces) + 1):\n",
    "                if i <= self.n_model:\n",
    "                    piece = pieces[:i]\n",
    "                else:\n",
    "                    piece = pieces[i - self.n_model:i]\n",
    "                \n",
    "                ngram_model_to_use = len(piece)\n",
    "                piece_lbl = \" \".join(piece)\n",
    "                if ngram_model_to_use in self.ngrams_freqs:\n",
    "                    den = float(self.total_counts[ngram_model_to_use - 1])\n",
    "                    num = float(self.ngrams_freqs[ngram_model_to_use].get(piece_lbl.lower(), 0))\n",
    "                    piece_prob = np.log10(num/den)\n",
    "                else:\n",
    "                    return -np.inf\n",
    "                total_prob += piece_prob\n",
    "            return total_prob\n",
    "        else:\n",
    "            return -100\n",
    "\n",
    "\n",
    "    def predictions(self, word):\n",
    "        \"\"\"\n",
    "        Autocomplete a word or a sentence using a HMM (Hidden Markov Model)\n",
    "        The HMM approximates the probability of a sentence with the n-gram model.\n",
    "        For instance for a 4-word sentence and a 3-gram model we have\n",
    "\n",
    "        P(w1 w2 w3 w4) = P(w1) * P(w2| w1) * P(w3| w1 w2) * P(w4| w1 w2 w3)\n",
    "\n",
    "        :param word: the input word(s)\n",
    "        \"\"\"\n",
    "        word = word.lower()\n",
    "        parts = word.split()\n",
    "        beginning = \"\"\n",
    "        if len(parts) >= self.n_model:\n",
    "            beginning = \" \".join(parts[:-self.n_model + 1])\n",
    "            word = \" \".join(parts[-self.n_model + 1:])\n",
    "        \n",
    "        if self.match_model == \"start\":\n",
    "            candidates = np.array(list(filter(lambda x: x.startswith(word), self.ngrams_keys.get(self.n_model, ''))))\n",
    "        if self.match_model == \"end\":\n",
    "            candidates = np.array(list(filter(lambda x: x.endswith(word), self.ngrams_keys.get(self.n_model, ''))))\n",
    "        #elif self.match_model == \"middle\":\n",
    "         #   candidates = np.array(list(filter(None, [key if word in key else None for key in self.ngrams_keys.get(self.n_model, '')])))[::-1]\n",
    "        else:\n",
    "            raise Exception(\"match_model can only be `start`, `end` or `middle`\")\n",
    "        #\n",
    "        if len(candidates) == 0:\n",
    "            return [], []\n",
    "        #\n",
    "        predictions = []\n",
    "        if len(candidates) >= 1:\n",
    "            for i in range(len(candidates)):\n",
    "                if beginning == \"\":\n",
    "                    predictions.append(\" \".join([beginning, candidates[i].replace(\"</END>\", \"\").capitalize()]).strip())\n",
    "                else:\n",
    "                    predictions.append(\" \".join([beginning.capitalize(), candidates[i].replace(\"</END>\", \"\")]).strip())\n",
    "        #\n",
    "        predictions = np.array(predictions)\n",
    "        probabilities = np.array(\n",
    "            [self.compute_prob_sentence(sentence) for sentence in predictions])\n",
    "        order = np.argsort(probabilities)[::-1]\n",
    "        predictions = list(predictions[order][:self.n_candidates])\n",
    "        probabilities = list(probabilities[order][:self.n_candidates])\n",
    "        #\n",
    "        return predictions, probabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hotelReviews = pd.read_csv('Hotel_Reviews-2.csv')\n",
    "nationality = ' United Kingdom '\n",
    "engReviews = hotelReviews.loc[hotelReviews['Reviewer_Nationality'] == nationality][['Positive_Review','Negative_Review']]\n",
    "allReviews = list(engReviews['Positive_Review'].append(engReviews['Negative_Review']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import langid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#corpus= []\n",
    "#uniqueUsefulTokens= set()\n",
    "\n",
    "#for i in range(len(allReviews)):\n",
    " #   review=\"\"\n",
    "  \n",
    "  #  if (langid.classify(review)[0]!='en'):\n",
    "   #     continue\n",
    "    #    review= re.sub('[^a-zA-Z]', ' ', review)\n",
    "     #   review=review.lower().split()\n",
    "      #  ps=PorterStemmer()\n",
    "       # review  = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))]\n",
    "    #for word in review:\n",
    "     #   uniqueUsefulTokens.add(word)\n",
    "    #review = ' '.join(review)\n",
    "    #corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Staff and service',\n",
       "  'Staff is very',\n",
       "  'Staff and rooms',\n",
       "  'Staff is courteous',\n",
       "  'Staff was also',\n",
       "  'Staff were all',\n",
       "  'Staff at the',\n",
       "  'Staff are efficient',\n",
       "  'Staff! this was'],\n",
       " [-7.0264093115293651,\n",
       "  -7.0264093115293651,\n",
       "  -7.0264093115293651,\n",
       "  -7.0264093115293651,\n",
       "  -7.3274393071933464,\n",
       "  -7.3274393071933464,\n",
       "  -7.3274393071933464,\n",
       "  -7.3274393071933464,\n",
       "  -8.2305292941852901])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "    #To train the autocomplete with your own data you need to have a list of sentences\n",
    "#and pass it as an argument of the class.\n",
    "\n",
    "#For example we can use the first two paragraphs from Robinson Crusoe\n",
    "\n",
    "from markov_autocomplete.autocomplete import Autocomplete\n",
    "\n",
    "#sentences = ['''I WAS born in the year 1632, in the city of York, of a good family,\\\n",
    "#though not of that country, my father being a foreigner of Bremen,\\\n",
    "#who settled first at Hull. He got a good estate by merchandise,\\\n",
    "#and leaving off his trade, lived afterwards at York,\\\n",
    "#from whence he had married my mother, whose relations were named Robinson,\\\n",
    "#a very good family in that country, and from whom I was called Robinson Kreutznaer;\\\n",
    "#but, by the usual corruption of words in England, we are now called - nay we call\\\n",
    "#ourselves and write our name - Crusoe; and so my companions always called me.\",\\\n",
    "#\"I had two elder brothers, one of whom was lieutenant-colonel to an English\\\n",
    "#regiment of foot in Flanders, formerly commanded by the famous Colonel Lockhart,\\\n",
    "#and was killed at the battle near Dunkirk against the Spaniards. What became of my\\\n",
    "#second brother I never knew, any more than my father or mother knew what became of me.''']\n",
    "\n",
    "sentences = ['''What an amazing experience with really over the top friendly staff!\n",
    "                This was one of my first stays with Marriott and they really did everything right. \n",
    "                Special bedding orders - everything was arranged. \n",
    "                Room size wishes - I was upgraded. \n",
    "                The room service was fast and the portion really big with reasonable prices. \n",
    "                No need to go somewhere else after a stressful day!\n",
    "                Standard decent Marriott hotel. \n",
    "                The staff are efficient and the room we had was really quite good - large, clean and comfortable beds. \n",
    "                The hotel bar - Champions - is the standard American type bar that Marriotts have.\n",
    "                The wait staff at the bar were very nice.\n",
    "                An emblematic hotel in the center of Athens.\n",
    "                This will take into account the meetings that take place in this hotel. \n",
    "                It is a great hotel with excellent modern decoration and clean spaces. \n",
    "                The staff is courteous and willing to serve you all with a smile. \n",
    "                The meeting rooms are quite large with comfortable seating and a good acoustic. \n",
    "                The food is very delicious and it is definitely worth visiting for a meal or a stay.\n",
    "                Probably one of the top hotels in Athens, with a top roof bar (Galaxy bar) overlooking the Acropolis and Lycabetus hills. \n",
    "                The hotel offers a number of restaurants and boasts an impressive outdoor swimming pool. \n",
    "                A great choice to stay while in Athens or visit for drinks or dinner.\n",
    "                What amazing views from the Terrace Suite at Four Seasons New York.  \n",
    "                The staff were all friendly, courteous, and discrete. The hotel lobby, bar, and lounge were beautiful and welcoming. \n",
    "                The room in which I stayed, had spectacular views.  \n",
    "                I will look forward to many returns at this particular Four Seasons Hotel, New York.\n",
    "                Super nice staff and rooms are not bad.  \n",
    "                Redone suite was super nice.  \n",
    "                Club room has drinks and good snacks.  \n",
    "                Hotel works as a stop for a night.   \n",
    "                Not sure I'd book if you want to be in the heart of Munich.   \n",
    "                It does have shops and restaurants around and good access to mass transit.\n",
    "                Room was clean, and was set up nicely. \n",
    "                Pool was really nice, and the view from the pool was fantastic. \n",
    "                At this point though, not having free wifi in the rooms (even though I'm a member of the club) is completely unacceptable.\n",
    "                This is my favorite hotel when visiting London. \n",
    "                The accommodations are excellent and the staff is very friendly and efficient. \n",
    "                The location is prime with superb views and adjacent parks for walking.\n",
    "                Oh yes a near by resistance is Buckingham Palace !!\n",
    "                Superior place , enjoyed our stay to the max , the location is excellent , just few minutes walking  to public transportation , there are quite nice good food restaurants and coffee shops very near the hotel ، Lebanese and Turkish restaurants too.\n",
    "                Hotel staff and service is great and is clean. \n",
    "                Only problem is the decor in lobby and restaurant area. \n",
    "                Instead of walking into a hotel in Greece, I felt like I was walking into a hotel in China. \n",
    "                I would prefer the greek experience when in Greece.  \n",
    "                They do book a very large amount of Asians. \n",
    "                I guess money talks.\n",
    "                This hotel had a nice breakfast and clean rooms. \n",
    "                Staff was also helpful. \n",
    "                The pool closes at 7. \n",
    "                Wonderful bakery across the street!''']\n",
    "\n",
    "ac = Autocomplete(model_path=\"ngram\",\n",
    "                  sentences=sentences,\n",
    "                  n_model=3,\n",
    "                  n_candidates=10,\n",
    "                  match_model=\"start\",\n",
    "                  min_freq=0,\n",
    "                  punctuations=\"\",\n",
    "                  lowercase=True)\n",
    "\n",
    "ac.predictions(\"staff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
