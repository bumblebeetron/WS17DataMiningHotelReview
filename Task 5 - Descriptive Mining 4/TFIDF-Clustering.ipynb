{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct \"Linkage Graph\"\n",
    "# Check what you can do with that graph\n",
    "# Check Mean Shift\n",
    "# Check non-k specific clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.sparse as sps\n",
    "import itertools\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import langid\n",
    "import re\n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "#from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change this to whichever CSV YOU WANT. But In the 2nd week, I constructed a csv file that also has the 'City' name column.\n",
    "# I'm using this csv for simplicity. You can construct the same by following my code in 2nd week.\n",
    "hotelReviews = pd.read_csv('C:/Users/deniz/Documents/HotelReviewsCountryCity.csv')\n",
    "cities = ['Paris', 'Amsterdam', 'London', 'Milan', 'Barcelona', 'Vienna']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For this, I've used Only UK reviews on Barcelona. Change it as you wish.\n",
    "# Don't use more than 30000 texts with the function tho. Because it gets impossible to construct the cos similarity matrix.\n",
    "\n",
    "#allPosRevs = hotelReviews.loc[(hotelReviews['City'] == 'Barcelona') & (hotelReviews['Reviewer_Nationality'] == ' United Kingdom ') & (hotelReviews['Positive_Review'] != 'No Positive')]['Positive_Review']\n",
    "allPosRevs = hotelReviews.loc[(hotelReviews['City'] == 'Barcelona') & (hotelReviews['Reviewer_Nationality'] == ' United Kingdom ')]['Positive_Review']\n",
    "\n",
    "#allPosRevs = hotelReviews['Positive_Review']\n",
    "#allPosWords = hotelReviews.loc[hotelReviews['Positive_Review'] != 'No Positive']['Positive_Review']\n",
    "#allReviews = hotelReviews.loc[(hotelReviews['Positive_Review'] != 'No Positive') & (hotelReviews['Negative_Review'] != 'No Negative')][['Positive_Review', 'Negative_Review']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def reviewWordList(reviews, wordLengthThreshold = 3, stopWordList = stopwords.words('English'), displayProgress = False):\n",
    "    allWords = []\n",
    "    i = 1\n",
    "    for posRev in reviews:\n",
    "        if i % ((len(reviews))/10) == 0 and displayProgress:\n",
    "            print '    ', 100 * (1.0 * i / len(reviews)), '% finished'\n",
    "        i+=1\n",
    "        allWords.append([f.split() for f in re.findall('\\d+|\\D+',posRev.lower())])\n",
    "\n",
    "    allWords = list(itertools.chain.from_iterable(list(itertools.chain.from_iterable(allWords))))\n",
    "    allWords = list(set(allWords))\n",
    "    revWordLst = []\n",
    "    for w in allWords:\n",
    "        if len(w) > wordLengthThreshold and w not in stopWordList:\n",
    "            revWordLst.append(w)\n",
    "    return revWordLst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getSimilarIndices(cosSim, simThreshold = .8, displayProgress = False):\n",
    "    simRevs = []\n",
    "\n",
    "    i = 1\n",
    "    for index in range(cosSim.shape[0]):\n",
    "        if i % (cosSim.shape[0]/10) == 0 and displayProgress:\n",
    "            print '    ', 100 * (1.0 * i / cosSim.shape[0]), '% finished'\n",
    "        i+=1\n",
    "        i_0 = np.array(cosSim[index].todense())[0]\n",
    "        sims = []\n",
    "        for where in np.argwhere(i_0 > simThreshold):\n",
    "            if where[0] != index:\n",
    "                #print where[0], lAPR[where[0]]\n",
    "                sims.append(where[0])\n",
    "        simRevs.append([index, sims])\n",
    "    return simRevs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getConnectionMatrix(simRevs, displayProgress = False):\n",
    "    connectionMatrix = sps.lil_matrix((len(simRevs),len(simRevs))).astype(np.bool)\n",
    "    i = 1\n",
    "    for s in simRevs:\n",
    "        if i % ((len(reviews))/10) == 0 and displayProgress:\n",
    "            print '    ', 100 * (1.0 * i / len(reviews)), '% finished'\n",
    "        i+=1\n",
    "        ind = s[0]\n",
    "        for j in s[1]:\n",
    "            connectionMatrix[ind,j] = 1\n",
    "    return connectionMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getSimilarTexts(reviews, simThreshold = .8, displayProgress = False, wordLengthThreshold = 3, stopWordList = stopwords.words('English'), getTFIDFMatrix = False):\n",
    "    if displayProgress:\n",
    "        print \"Extracting Important Texts\"\n",
    "    rwl = reviewWordList(reviews, wordLengthThreshold = 3, stopWordList = stopwords.words('English'), displayProgress=displayProgress)\n",
    "    \n",
    "    if displayProgress:\n",
    "        print \"Constructing TF-IDF Vectorizer\"\n",
    "    vectorizer = TfidfVectorizer(stop_words=stopwords.words('English'), vocabulary=rwl)\n",
    "    \n",
    "    if displayProgress:\n",
    "        print \"Constructing Feature Matrix\"\n",
    "    featureMatrix = vectorizer.fit_transform(reviews)\n",
    "    \n",
    "    if getTFIDFMatrix:\n",
    "        return featureMatrix\n",
    "    \n",
    "    if displayProgress:\n",
    "        print \"Constructing Cosine Similarity Matrix\"\n",
    "    cosSim = cosine_similarity(featureMatrix, Y=None, dense_output=False)\n",
    "    \n",
    "    if displayProgress:\n",
    "        print \"Extracting Similar Reviews\"\n",
    "    simRevs = getSimilarIndices(cosSim, simThreshold=simThreshold, displayProgress=displayProgress)\n",
    "    \n",
    "    return simRevs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     9.9985579003 % finished\n",
      "     19.9971158006 % finished\n",
      "     29.9956737009 % finished\n",
      "     39.9942316012 % finished\n",
      "     49.9927895015 % finished\n",
      "     59.9913474018 % finished\n",
      "     69.9899053021 % finished\n",
      "     79.9884632024 % finished\n",
      "     89.9870211027 % finished\n",
      "     99.985579003 % finished\n",
      "     9.9985579003 % finished\n",
      "     19.9971158006 % finished\n",
      "     29.9956737009 % finished\n",
      "     39.9942316012 % finished\n",
      "     49.9927895015 % finished\n",
      "     59.9913474018 % finished\n",
      "     69.9899053021 % finished\n",
      "     79.9884632024 % finished\n",
      "     89.9870211027 % finished\n",
      "     99.985579003 % finished\n"
     ]
    }
   ],
   "source": [
    "displayProgress = True\n",
    "simThreshold = 0.8\n",
    "wordLengthThreshold = 3\n",
    "\n",
    "reviews = allPosRevs\n",
    "\n",
    "rwl = reviewWordList(reviews, wordLengthThreshold = wordLengthThreshold, stopWordList = stopwords.words('English'), displayProgress=displayProgress)\n",
    "featureMatrix = TfidfVectorizer(stop_words=stopwords.words('English'), vocabulary=rwl).fit_transform(reviews)\n",
    "cosSim = cosine_similarity(featureMatrix, Y=None, dense_output=False)\n",
    "simRevs = getSimilarIndices(cosSim, simThreshold=0.8, displayProgress=displayProgress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     9.9985579003 % finished\n",
      "     19.9971158006 % finished\n",
      "     29.9956737009 % finished\n",
      "     39.9942316012 % finished\n",
      "     49.9927895015 % finished\n",
      "     59.9913474018 % finished\n",
      "     69.9899053021 % finished\n",
      "     79.9884632024 % finished\n",
      "     89.9870211027 % finished\n",
      "     99.985579003 % finished\n"
     ]
    }
   ],
   "source": [
    "connectionMatrix = getConnectionMatrix(simRevs, displayProgress=displayProgress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr1inds = np.array(connectionMatrix.sum(axis=0))[0].argsort()\n",
    "sortedConn = connectionMatrix[arr1inds[::-1]]\n",
    "\n",
    "dcImg = Image.new('1', sortedConn.shape)\n",
    "pixels = dcImg.load()\n",
    "\n",
    "for i in range(sortedConn.shape[0]):\n",
    "    for j in range(sortedConn.shape[0]):\n",
    "        pixels[i,j] = 1\n",
    "\n",
    "nzs = sortedConn.nonzero()\n",
    "        \n",
    "for i in range(len(nzs[0])):\n",
    "    pixels[nzs[0][i], nzs[1][i]] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcImg.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcImg = Image.new('1', connectionMatrix.shape)\n",
    "pixels = dcImg.load()\n",
    "\n",
    "for i in range(connectionMatrix.shape[0]):\n",
    "    for j in range(connectionMatrix.shape[0]):\n",
    "        pixels[i,j] = 1\n",
    "\n",
    "nzs = connectionMatrix.nonzero()\n",
    "        \n",
    "for i in range(len(nzs[0])):\n",
    "    pixels[nzs[0][i], nzs[1][i]] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(connectionMatrix.shape[0]):\n",
    "    for j in range(connectionMatrix.shape[0]):\n",
    "        pixels[i,j] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "nzs = connectionMatrix.nonzero()\n",
    "        \n",
    "for i in range(len(nzs[0])):\n",
    "    pixels[nzs[0][i], nzs[1][i]] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dcImg = Image.new('1', densecon.shape)\n",
    "pixels = dcImg.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "dcImg.save('file.bmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dcImg.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imsave('filename.png', densecon, cmap=cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.fromarray(densecon*255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img.save('image.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Usage: \n",
    "# Chagne the displayProgress to False if you don't want to see the progress of the algorithm. \n",
    "# Change the simThreshold as you wish to meet your demands. The higher, the more similar two texts. \n",
    "# Set to 1 if you wanna find duplicates\n",
    "# Change wordLengthThreshold to the maximum length of significant words (for tf-idf). The default is 3. IE: words with length 1 or 2 won't count\n",
    "# Change stopWordList to any language stopowrds you want. The default is stopwords.words('English')\n",
    "\n",
    "# Input 'allPosRevs' is the pandas list of all positive reviews I've extracted in the 3rd block. \n",
    "# It has to be a single column pandas dataframe (This is the equivalent of pandas list)\n",
    "\n",
    "featureMatrix = getSimilarTexts(allPosRevs, simThreshold = .8, displayProgress=True, getTFIDFMatrix=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import SpectralClustering\n",
    "#mat = np.matrix([[1.,.1,.6,.4],[.1,1.,.1,.2],[.6,.1,1.,.7],[.4,.2,.7,1.]])\n",
    "#SpectralClustering(2).fit_predict(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster import  hierarchy\n",
    "threshold = 0.1\n",
    "#Z = hierarchy.linkage(featureMatrix,\"average\", metric=\"cosine\")\n",
    "C = hierarchy.fcluster(featureMatrix, threshold, criterion=\"distance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bandwidth = estimate_bandwidth(featureMatrix, quantile=0.2, n_samples=500)\n",
    "\n",
    "ms = MeanShift(bin_seeding=True)\n",
    "ms.fit(featureMatrix)\n",
    "labels = ms.labels_\n",
    "cluster_centers = ms.cluster_centers_\n",
    "\n",
    "labels_unique = np.unique(labels)\n",
    "n_clusters_ = len(labels_unique)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
