{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct \"Linkage Graph\"\n",
    "# Check what you can do with that graph\n",
    "# Check Mean Shift\n",
    "# Check non-k specific clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\deniz\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.sparse as sps\n",
    "import itertools\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import langid\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "#from nltk.stem.porter import PorterStemmer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Change this to whichever CSV YOU WANT. But In the 2nd week, I constructed a csv file that also has the 'City' name column.\n",
    "# I'm using this csv for simplicity. You can construct the same by following my code in 2nd week.\n",
    "hotelReviews = pd.read_csv('C:/Users/deniz/Documents/HotelReviewsCountryCity.csv')\n",
    "cities = ['Paris', 'Amsterdam', 'London', 'Milan', 'Barcelona', 'Vienna']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For this, I've used Only UK reviews on Barcelona. Change it as you wish.\n",
    "# Don't use more than 30000 texts with the function tho. Because it gets impossible to construct the cos similarity matrix.\n",
    "\n",
    "#allPosRevs = hotelReviews.loc[(hotelReviews['City'] == 'Barcelona') & (hotelReviews['Reviewer_Nationality'] == ' United Kingdom ') & (hotelReviews['Positive_Review'] != 'No Positive')]['Positive_Review']\n",
    "allPosRevs = hotelReviews.loc[(hotelReviews['City'] == 'Barcelona') & (hotelReviews['Reviewer_Nationality'] == ' United Kingdom ')]['Positive_Review']\n",
    "\n",
    "#allPosRevs = hotelReviews['Positive_Review']\n",
    "#allPosWords = hotelReviews.loc[hotelReviews['Positive_Review'] != 'No Positive']['Positive_Review']\n",
    "#allReviews = hotelReviews.loc[(hotelReviews['Positive_Review'] != 'No Positive') & (hotelReviews['Negative_Review'] != 'No Negative')][['Positive_Review', 'Negative_Review']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def reviewWordList(reviews, wordLengthThreshold = 3, stopWordList = stopwords.words('English'), displayProgress = False):\n",
    "    allWords = []\n",
    "    i = 1\n",
    "    for posRev in reviews:\n",
    "        if i % ((len(reviews))/10) == 0 and displayProgress:\n",
    "            print '    ', 100 * (1.0 * i / len(reviews)), '% finished'\n",
    "        i+=1\n",
    "        allWords.append([f.split() for f in re.findall('\\d+|\\D+',posRev.lower())])\n",
    "\n",
    "    allWords = list(itertools.chain.from_iterable(list(itertools.chain.from_iterable(allWords))))\n",
    "    allWords = list(set(allWords))\n",
    "    revWordLst = []\n",
    "    for w in allWords:\n",
    "        if len(w) > wordLengthThreshold and w not in stopWordList:\n",
    "            revWordLst.append(w)\n",
    "    return revWordLst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getSimilarIndices(cosSim, simThreshold = .8, displayProgress = False):\n",
    "    simRevs = []\n",
    "\n",
    "    i = 1\n",
    "    for index in range(cosSim.shape[0]):\n",
    "        if i % (cosSim.shape[0]/10) == 0 and displayProgress:\n",
    "            print '    ', 100 * (1.0 * i / cosSim.shape[0]), '% finished'\n",
    "        i+=1\n",
    "        i_0 = np.array(cosSim[index].todense())[0]\n",
    "        sims = []\n",
    "        for where in np.argwhere(i_0 > simThreshold):\n",
    "            if where[0] != index:\n",
    "                #print where[0], lAPR[where[0]]\n",
    "                sims.append(where[0])\n",
    "        simRevs.append([index, sims])\n",
    "    return simRevs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getSimilarTexts(reviews, simThreshold = .8, displayProgress = False, wordLengthThreshold = 3, stopWordList = stopwords.words('English'), getTFIDFMatrix = False):\n",
    "    if displayProgress:\n",
    "        print \"Extracting Important Texts\"\n",
    "    rwl = reviewWordList(reviews, wordLengthThreshold = 3, stopWordList = stopwords.words('English'), displayProgress=displayProgress)\n",
    "    \n",
    "    if displayProgress:\n",
    "        print \"Constructing TF-IDF Vectorizer\"\n",
    "    vectorizer = TfidfVectorizer(stop_words=stopwords.words('English'), vocabulary=rwl)\n",
    "    \n",
    "    if displayProgress:\n",
    "        print \"Constructing Feature Matrix\"\n",
    "    featureMatrix = vectorizer.fit_transform(reviews)\n",
    "    \n",
    "    if getTFIDFMatrix:\n",
    "        return featureMatrix\n",
    "    \n",
    "    if displayProgress:\n",
    "        print \"Constructing Cosine Similarity Matrix\"\n",
    "    cosSim = cosine_similarity(featureMatrix, Y=None, dense_output=False)\n",
    "    \n",
    "    if displayProgress:\n",
    "        print \"Extracting Similar Reviews\"\n",
    "    simRevs = getSimilarIndices(cosSim, simThreshold=simThreshold, displayProgress=displayProgress)\n",
    "    \n",
    "    return simRevs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Important Texts\n",
      "     9.9985579003 % finished\n",
      "     19.9971158006 % finished\n",
      "     29.9956737009 % finished\n",
      "     39.9942316012 % finished\n",
      "     49.9927895015 % finished\n",
      "     59.9913474018 % finished\n",
      "     69.9899053021 % finished\n",
      "     79.9884632024 % finished\n",
      "     89.9870211027 % finished\n",
      "     99.985579003 % finished\n",
      "Constructing TF-IDF Vectorizer\n",
      "Constructing Feature Matrix\n"
     ]
    }
   ],
   "source": [
    "# Usage: \n",
    "# Chagne the displayProgress to False if you don't want to see the progress of the algorithm. \n",
    "# Change the simThreshold as you wish to meet your demands. The higher, the more similar two texts. \n",
    "# Set to 1 if you wanna find duplicates\n",
    "# Change wordLengthThreshold to the maximum length of significant words (for tf-idf). The default is 3. IE: words with length 1 or 2 won't count\n",
    "# Change stopWordList to any language stopowrds you want. The default is stopwords.words('English')\n",
    "\n",
    "# Input 'allPosRevs' is the pandas list of all positive reviews I've extracted in the 3rd block. \n",
    "# It has to be a single column pandas dataframe (This is the equivalent of pandas list)\n",
    "\n",
    "featureMatrix = getSimilarTexts(allPosRevs, simThreshold = .8, displayProgress=True, getTFIDFMatrix=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\cluster\\spectral.py:433: UserWarning: The spectral clustering API has changed. ``fit``now constructs an affinity matrix from data. To use a custom affinity matrix, set ``affinity=precomputed``.\n",
      "  warnings.warn(\"The spectral clustering API has changed. ``fit``\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import SpectralClustering\n",
    "#mat = np.matrix([[1.,.1,.6,.4],[.1,1.,.1,.2],[.6,.1,1.,.7],[.4,.2,.7,1.]])\n",
    "#SpectralClustering(2).fit_predict(mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Linkage matrix 'Z' must contain doubles.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-171a4dd0765d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mthreshold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#Z = hierarchy.linkage(featureMatrix,\"average\", metric=\"cosine\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhierarchy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfcluster\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatureMatrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"distance\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\scipy\\cluster\\hierarchy.py\u001b[0m in \u001b[0;36mfcluster\u001b[1;34m(Z, t, criterion, depth, R, monocrit)\u001b[0m\n\u001b[0;32m   1643\u001b[0m     \"\"\"\n\u001b[0;32m   1644\u001b[0m     \u001b[0mZ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1645\u001b[1;33m     \u001b[0mis_valid_linkage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthrow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Z'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1646\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1647\u001b[0m     \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mZ\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\scipy\\cluster\\hierarchy.py\u001b[0m in \u001b[0;36mis_valid_linkage\u001b[1;34m(Z, warning, throw, name)\u001b[0m\n\u001b[0;32m   1450\u001b[0m                             name_str)\n\u001b[0;32m   1451\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mZ\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1452\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Linkage matrix %smust contain doubles.'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mname_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1453\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mZ\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1454\u001b[0m             raise ValueError('Linkage matrix %smust have shape=2 (i.e. be '\n",
      "\u001b[1;31mTypeError\u001b[0m: Linkage matrix 'Z' must contain doubles."
     ]
    }
   ],
   "source": [
    "from scipy.cluster import  hierarchy\n",
    "threshold = 0.1\n",
    "#Z = hierarchy.linkage(featureMatrix,\"average\", metric=\"cosine\")\n",
    "C = hierarchy.fcluster(featureMatrix, threshold, criterion=\"distance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-8aa330065016>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMeanShift\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbin_seeding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatureMatrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mcluster_centers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcluster_centers_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\cluster\\mean_shift_.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    385\u001b[0m             \u001b[0mSamples\u001b[0m \u001b[0mto\u001b[0m \u001b[0mcluster\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m         \"\"\"\n\u001b[1;32m--> 387\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    388\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcluster_centers_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels_\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    389\u001b[0m             mean_shift(X, bandwidth=self.bandwidth, seeds=self.seeds,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    378\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    379\u001b[0m         array = _ensure_sparse_format(array, accept_sparse, dtype, copy,\n\u001b[1;32m--> 380\u001b[1;33m                                       force_all_finite)\n\u001b[0m\u001b[0;32m    381\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m         \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_ensure_sparse_format\u001b[1;34m(spmatrix, accept_sparse, dtype, copy, force_all_finite)\u001b[0m\n\u001b[0;32m    241\u001b[0m     \"\"\"\n\u001b[0;32m    242\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0maccept_sparse\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 243\u001b[1;33m         raise TypeError('A sparse matrix was passed, but dense '\n\u001b[0m\u001b[0;32m    244\u001b[0m                         \u001b[1;34m'data is required. Use X.toarray() to '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    245\u001b[0m                         'convert to a dense numpy array.')\n",
      "\u001b[1;31mTypeError\u001b[0m: A sparse matrix was passed, but dense data is required. Use X.toarray() to convert to a dense numpy array."
     ]
    }
   ],
   "source": [
    "#bandwidth = estimate_bandwidth(featureMatrix, quantile=0.2, n_samples=500)\n",
    "\n",
    "ms = MeanShift(bin_seeding=True)\n",
    "ms.fit(featureMatrix)\n",
    "labels = ms.labels_\n",
    "cluster_centers = ms.cluster_centers_\n",
    "\n",
    "labels_unique = np.unique(labels)\n",
    "n_clusters_ = len(labels_unique)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
