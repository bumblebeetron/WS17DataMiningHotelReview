{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from nltk import ngrams\n",
    "from collections import Counter\n",
    "\n",
    "class Autocomplete():\n",
    "    \"\"\"\n",
    "To train the autocomplete with your own data you need to have a list of sentences\n",
    "and pass it as an argument of the class.\n",
    "\n",
    "For example we can use the first two paragraphs from Robinson Crusoe\n",
    "\n",
    "from markov_autocomplete.autocomplete import Autocomplete\n",
    "\n",
    "sentences = ['''I WAS born in the year 1632, in the city of York, of a good family,\\\n",
    "though not of that country, my father being a foreigner of Bremen,\\\n",
    "who settled first at Hull. He got a good estate by merchandise,\\\n",
    "and leaving off his trade, lived afterwards at York,\\\n",
    "from whence he had married my mother, whose relations were named Robinson,\\\n",
    "a very good family in that country, and from whom I was called Robinson Kreutznaer;\\\n",
    "but, by the usual corruption of words in England, we are now called - nay we call\\\n",
    "ourselves and write our name - Crusoe; and so my companions always called me.\",\\\n",
    "\"I had two elder brothers, one of whom was lieutenant-colonel to an English\\\n",
    "regiment of foot in Flanders, formerly commanded by the famous Colonel Lockhart,\\\n",
    "and was killed at the battle near Dunkirk against the Spaniards. What became of my\\\n",
    "second brother I never knew, any more than my father or mother knew what became of me.''']\n",
    "\n",
    "ac = Autocomplete(model_path=\"ngram\",\n",
    "                  sentences=sentences,\n",
    "                  n_model=3,\n",
    "                  n_candidates=10,\n",
    "                  match_model=\"middle\",\n",
    "                  min_freq=0,\n",
    "                  punctuations=\"\",\n",
    "                  lowercase=True)\n",
    "\n",
    "ac.predictions(\"country\")\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model_path=\"./\", sentences=None, n_model=3, n_candidates=10, match_model=\"middle\",\n",
    "                 min_freq=5, punctuations=\"\"\"!\"#$%&\\'()*+,./:;<=>?@[\\\\]^_{|}~\"\"\", lowercase=True):\n",
    "        # Model parameters\n",
    "        # order of the n-gram to use for the autocomplete\n",
    "        self.n_model = n_model\n",
    "        # number of candidates suggested sentences to show\n",
    "        self.n_candidates = n_candidates\n",
    "        # path to the folder that stores the language model\n",
    "        self.model_path = model_path\n",
    "        # type of autocomplete model\n",
    "        # `start`, `end` of `middle`\n",
    "        self.match_model = match_model\n",
    "        # do not consider ngrams that appear less than this value when generating the language model\n",
    "        self.min_freq = min_freq\n",
    "        # punctuations to remove\n",
    "        self.punctuations = punctuations\n",
    "        # lowercase the sentences?\n",
    "        self.lowercase = lowercase\n",
    "        # list of sentences to use to train the model\n",
    "        if sentences is None:\n",
    "            sentences = []\n",
    "        self.sentences = sentences\n",
    "\n",
    "        if not os.path.isdir(self.model_path):\n",
    "            os.makedirs(self.model_path)\n",
    "\n",
    "        # loading the language model\n",
    "        for N in range(1, self.n_model + 1):\n",
    "            filename = self.model_path + \"/\" + str(N) + \"-grams.pickle\"\n",
    "            if not os.path.exists(filename):\n",
    "                # if no language model is found, then it is computed\n",
    "                # remove the dashes and the bendy apostrophe\n",
    "                if not self.sentences:\n",
    "                    raise Exception(\"You need to give a sample sentences to train the model!\")\n",
    "                self.compute_language_model()\n",
    "\n",
    "        # ngrams_freqs is a dictionary whose keys are the ngrams labels and the values their counts\n",
    "        self.ngrams_freqs = dict()\n",
    "        for N in range(1, self.n_model + 1):\n",
    "            filename = self.model_path + \"/\" + str(N) + \"-grams.pickle\"\n",
    "            with open(filename, \"rb\") as f:\n",
    "                self.ngrams_freqs[N] = pickle.load(f)\n",
    "\n",
    "        # saving the ngrams_freqs keys in a separate dictionary\n",
    "        self.ngrams_keys = dict()\n",
    "        for N in range(1, self.n_model + 1):\n",
    "            self.ngrams_keys[N] = list(self.ngrams_freqs[N].keys())\n",
    "\n",
    "        # saving the total counts\n",
    "        self.total_counts = [sum(self.ngrams_freqs[N].values()) for N in range(1, self.n_model + 1)]\n",
    "\n",
    "\n",
    "    def get_ngrams(self, sentence, n=1):\n",
    "        \"\"\"\n",
    "        Given a sentence returns a list of its n-grams\n",
    "        \"\"\"\n",
    "        # remove punctuation\n",
    "        if self.punctuations != \"\":\n",
    "            sentence = re.sub('[' + self.punctuations + ']', ' ', sentence).strip()\n",
    "        if self.lowercase:\n",
    "            sentence = sentence.lower()\n",
    "        # generate tokens\n",
    "        if n > 1:\n",
    "            sentence = [\" \".join(n) for n in ngrams(sentence.split(), n, pad_right=True, right_pad_symbol='</END>')]\n",
    "        else:\n",
    "            sentence = sentence.split()\n",
    "        # return the token\n",
    "        # filter for empty string\n",
    "        return list(filter(None, sentence))\n",
    "\n",
    "\n",
    "    def compute_language_model(self):\n",
    "        \"\"\"\n",
    "        Given a list of sentences compute the n-grams\n",
    "        \"\"\"\n",
    "        if len(self.sentences) < 1e4:\n",
    "            for N in range(1, self.n_model + 1):\n",
    "                ngrams_list = []\n",
    "                for sentence in self.sentences:\n",
    "                    ngrams_sentence = self.get_ngrams(sentence, n=N)\n",
    "                    ngrams_list.extend(ngrams_sentence)\n",
    "                ngrams_freqs = Counter(ngrams_list)\n",
    "                filename = self.model_path + \"/\" + str(N) + \"-grams.pickle\"\n",
    "                with open(filename, \"wb\") as f:\n",
    "                    pickle.dump(ngrams_freqs, f)\n",
    "                print(\"Saving the %s-grams in %s\" % (N, filename))\n",
    "        else:\n",
    "            try:\n",
    "                from pyspark import SparkContext, SparkConf\n",
    "            except:\n",
    "                raise ImportError(\"pySpark not found! Please go to http://spark.apache.org/downloads.html\")\n",
    "            else:\n",
    "                # If there are more than 100,000 sentences use Spark to compute the n-grams\n",
    "                conf = SparkConf().setMaster(\"local\").setAppName(\"ComputeLanguageModel\")\n",
    "                sc = SparkContext(conf=conf)\n",
    "                sentences = sc.parallelize(self.sentences)\n",
    "\n",
    "                for N in range(1, self.n_model + 1):\n",
    "                    ngrams_freqs = sentences.flatMap(lambda x: self.get_ngrams(x, n=N))\n",
    "                    ngrams_freqs = ngrams_freqs.map(lambda word: (word, 1)).reduceByKey(lambda x, y: x + y).collect()\n",
    "                    ngrams_freqs.sort(key=lambda x: -x[1])\n",
    "                    ngrams_freqs = list(filter(lambda x: x[1] > self.min_freq, ngrams_freqs))\n",
    "                    ngrams_freqs = dict(ngrams_freqs)\n",
    "                    filename = self.model_path + \"/\" + str(N) + \"-grams.pickle\"\n",
    "                    with open(filename, \"wb\") as f:\n",
    "                        pickle.dump(ngrams_freqs, f)\n",
    "                        print(\"Saving the %s-grams in %s\" % (N, filename))\n",
    "\n",
    "                sc.stop()\n",
    "\n",
    "\n",
    "    def compute_prob_sentence(self, sentence):\n",
    "        \"\"\"\n",
    "        Given a sentence, return the log probability of that sentence using the n-gram approximation\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        if sentence != \"\":\n",
    "            total_prob = 0\n",
    "            pieces = sentence.split()\n",
    "            for i in range(1, len(pieces) + 1):\n",
    "                if i <= self.n_model:\n",
    "                    piece = pieces[:i]\n",
    "                else:\n",
    "                    piece = pieces[i - self.n_model:i]\n",
    "                #\n",
    "                ngram_model_to_use = len(piece)\n",
    "                piece_lbl = \" \".join(piece)\n",
    "                if ngram_model_to_use in self.ngrams_freqs:\n",
    "                    den = float(self.total_counts[ngram_model_to_use - 1])\n",
    "                    num = float(self.ngrams_freqs[ngram_model_to_use].get(piece_lbl.lower(), 0))\n",
    "                    piece_prob = np.log10(num/den)\n",
    "                else:\n",
    "                    return -np.inf\n",
    "                total_prob += piece_prob\n",
    "            return total_prob\n",
    "        else:\n",
    "            return -100\n",
    "\n",
    "\n",
    "    def predictions(self, word):\n",
    "        \"\"\"\n",
    "        Autocomplete a word or a sentence using a HMM (Hidden Markov Model)\n",
    "        The HMM approximates the probability of a sentence with the n-gram model.\n",
    "        For instance for a 4-word sentence and a 3-gram model we have\n",
    "\n",
    "        P(w1 w2 w3 w4) = P(w1) * P(w2| w1) * P(w3| w1 w2) * P(w4| w1 w2 w3)\n",
    "\n",
    "        :param word: the input word(s)\n",
    "        \"\"\"\n",
    "        word = word.lower()\n",
    "        parts = word.split()\n",
    "        beginning = \"\"\n",
    "        if len(parts) >= self.n_model:\n",
    "            beginning = \" \".join(parts[:-self.n_model + 1])\n",
    "            word = \" \".join(parts[-self.n_model + 1:])\n",
    "        #\n",
    "        if self.match_model == \"start\":\n",
    "            candidates = np.array(list(filter(lambda x: x.startswith(word), self.ngrams_keys.get(self.n_model, ''))))\n",
    "        elif self.match_model == \"end\":\n",
    "            candidates = np.array(list(filter(lambda x: x.endswith(word), self.ngrams_keys.get(self.n_model, ''))))\n",
    "        elif self.match_model == \"middle\":\n",
    "            candidates = np.array(list(filter(None, [key if word in key else None for key in self.ngrams_keys.get(self.n_model, '')])))[::-1]\n",
    "        else:\n",
    "            raise Exception(\"match_model can only be `start`, `end` or `middle`\")\n",
    "        #\n",
    "        if len(candidates) == 0:\n",
    "            return [], []\n",
    "        #\n",
    "        predictions = []\n",
    "        if len(candidates) >= 1:\n",
    "            for i in range(len(candidates)):\n",
    "                if beginning == \"\":\n",
    "                    predictions.append(\" \".join([beginning, candidates[i].replace(\"</END>\", \"\").capitalize()]).strip())\n",
    "                else:\n",
    "                    predictions.append(\" \".join([beginning.capitalize(), candidates[i].replace(\"</END>\", \"\")]).strip())\n",
    "        #\n",
    "        predictions = np.array(predictions)\n",
    "        probabilities = np.array(\n",
    "            [self.compute_prob_sentence(sentence) for sentence in predictions])\n",
    "        order = np.argsort(probabilities)[::-1]\n",
    "        predictions = list(predictions[order][:self.n_candidates])\n",
    "        probabilities = list(probabilities[order][:self.n_candidates])\n",
    "        #\n",
    "        return predictions, probabilities\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
